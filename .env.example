# ============================================================================
# OFFLINE WIKIPEDIA VECTOR SEARCH API - ENVIRONMENT CONFIGURATION EXAMPLE
# ============================================================================
# Copy this file to .env and customize the values for your environment

# Qdrant Vector Database Configuration
QDRANT_HOST=localhost
QDRANT_PORT=6333

# Data Storage Configuration
DATA_DIR=./data
MODELS_DIR=./models

# Embedding Model Configuration
EMBEDDING_MODEL=paraphrase-multilingual-MiniLM-L12-v2

# Local LLM Configuration
LLM_TYPE=ollama
# Options: ollama, transformers

# Ollama Configuration (when LLM_TYPE=ollama)
LLM_MODEL=phi3:mini
# Popular lightweight models:
# - phi3:mini (2.3GB) - Best balance of quality and speed
# - llama3.2:1b (1.3GB) - Very fast, good for limited resources
# - gemma2:2b (1.6GB) - Good alternative
# - qwen2:1.5b (934MB) - Ultra lightweight
OLLAMA_HOST=localhost
OLLAMA_PORT=11434

# Transformers Configuration (when LLM_TYPE=transformers)
TRANSFORMERS_MODEL=microsoft/DialoGPT-small
# Popular models for local use:
# - microsoft/DialoGPT-small - Good for conversations
# - gpt2 - Classic generative model
# - distilgpt2 - Lighter version of GPT-2

# LLM Generation Parameters
LLM_MAX_TOKENS=512
LLM_TEMPERATURE=0.3
LLM_TOP_P=0.9
LLM_TOP_K=50

# Wikipedia Processing Configuration
MAX_ARTICLES_DEFAULT=1000
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
MAX_CHUNKS_PER_ARTICLE=20

# API Configuration
API_HOST=0.0.0.0
API_PORT=9000
API_RELOAD=true

# Logging Configuration
LOG_LEVEL=INFO

# Performance Configuration
BATCH_SIZE=32
MAX_WORKERS=4
ENABLE_GPU=false

# Security Configuration
CORS_ORIGINS=*

# Cache Configuration
ENABLE_EMBEDDING_CACHE=true
CACHE_DIR=./cache

# Development Configuration
DEBUG_MODE=false
PROFILE_PERFORMANCE=false

# ============================================================================
# DOCKER OVERRIDES (automatically used when running in containers)
# ============================================================================
# QDRANT_HOST=qdrant
# OLLAMA_HOST=ollama
# DATA_DIR=/app/data
# MODELS_DIR=/app/models