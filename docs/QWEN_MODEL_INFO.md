# Qwen 2.5 (7B) - Informa√ß√µes do Modelo

## Sobre o Modelo

**Qwen 2.5** √© um modelo de linguagem desenvolvido pela Alibaba Cloud, otimizado para:
- ‚úÖ **Tool Calling** (Function Calling)
- ‚úÖ **RAG (Retrieval-Augmented Generation)**
- ‚úÖ **Multil√≠ngue** (Chin√™s, Ingl√™s, Portugu√™s e mais)
- ‚úÖ **Racioc√≠nio l√≥gico**
- ‚úÖ **Gera√ß√£o de c√≥digo**

## Especifica√ß√µes T√©cnicas

- **Tamanho**: ~4.7 GB
- **Par√¢metros**: 7 bilh√µes
- **Quantiza√ß√£o**: Q4_0 (4-bit)
- **Contexto**: 128K tokens
- **Fam√≠lia**: Qwen

## Capacidades

### ‚úÖ Tool Calling
O modelo suporta **function calling** nativo, permitindo:
- Chamar fun√ß√µes externas durante a gera√ß√£o
- Integrar com APIs e ferramentas
- Executar a√ß√µes baseadas em contexto
- Retornar resultados estruturados (JSON)

### ‚úÖ RAG Otimizado
Excelente para sistemas de busca vetorial:
- Compreens√£o profunda de contexto
- S√≠ntese de m√∫ltiplos documentos
- Respostas precisas baseadas em evid√™ncias
- Cita√ß√£o de fontes

### ‚úÖ Multil√≠ngue
Suporta mais de 29 idiomas, incluindo:
- Portugu√™s (PT-BR e PT-PT)
- Ingl√™s
- Espanhol
- Chin√™s (nativo)

## Uso no Projeto

O modelo est√° configurado em:
- **`.env`**: `LLM_MODEL=qwen2.5:7b`
- **`wikipediaOfflineService.py`**: Modelo padr√£o

### Exemplo de Uso

```python
# O servi√ßo usa automaticamente o qwen2.5:7b
resultado = wikipedia_offline_service.perguntar(
    "Qual a capital do Brasil?",
    limite=5
)
```

### Tool Calling Example

```python
# Definir ferramentas dispon√≠veis
tools = [
    {
        "type": "function",
        "function": {
            "name": "buscar_wikipedia",
            "description": "Busca informa√ß√µes na Wikipedia offline",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "Termo de busca"
                    }
                },
                "required": ["query"]
            }
        }
    }
]

# Usar com Ollama
response = ollama.chat(
    model='qwen2.5:7b',
    messages=[{'role': 'user', 'content': 'Busque informa√ß√µes sobre Python'}],
    tools=tools
)
```

## Compara√ß√£o com phi3:mini

| Caracter√≠stica | phi3:mini | qwen2.5:7b |
|----------------|-----------|------------|
| Tamanho | 2.2 GB | 4.7 GB |
| Par√¢metros | 3.8B | 7B |
| Tool Calling | ‚ùå N√£o | ‚úÖ Sim |
| Contexto | 128K | 128K |
| Multil√≠ngue | Limitado | Excelente |
| RAG | Bom | Excelente |
| Velocidade | Mais r√°pido | Moderado |

## Performance Esperada

### Vantagens
- Respostas mais precisas em portugu√™s
- Melhor compreens√£o de contexto
- Suporte nativo a ferramentas
- S√≠ntese de documentos superior

### Considera√ß√µes
- Requer mais RAM (~6-8 GB)
- Infer√™ncia ligeiramente mais lenta
- Melhor com GPU (mas funciona em CPU)

## Pr√≥ximos Passos

1. ‚úÖ Modelo baixado e configurado
2. ‚è≥ Reiniciar containers Docker
3. ‚è≥ Testar interface web
4. ‚è≥ Implementar tool calling no RAG
5. ‚è≥ Adicionar mais artigos da Wikipedia

## üÜï Novidade

- Agora o sistema suporta troca din√¢mica de modelo de embedding via API e script utilit√°rio.

## Refer√™ncias

- [Qwen Documentation](https://qwen.readthedocs.io/)
- [Ollama Qwen Models](https://ollama.ai/library/qwen2.5)
- [Tool Calling Guide](https://github.com/QwenLM/Qwen/blob/main/examples/function_calling.md)
